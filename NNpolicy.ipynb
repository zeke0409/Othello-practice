{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-08T14:43:01.461Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "2.1.0\n"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPool2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten\n",
    "from tensorflow.keras.utils import plot_model, to_categorical\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# ヘルパーライブラリのインポート\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データの読み込み\n",
    "http://meipuru-344.hatenablog.com/entry/2017/11/27/205448   より\n",
    "\n",
    "中身の説明\n",
    "\n",
    "1 1 1 1 1 1 1 1 1 1 2 1 2 2 2 1 1 1 1 2 1 1 2 1 1 2 1 1 1 1 2 1 1 2 1 1 1 1 2 1 1 2 1 2 1 2 2 1 1 1 1 1 2 2 2 1 1 1 1 2 2 2 0 0 7 8 W 2\n",
    "\n",
    "こんな感じのデータが大量に入っていると思います\n",
    "\n",
    "八文字ごとに改行します\n",
    "\n",
    "1 1 1 1 1 1 1 1\n",
    "1 1 2 1 2 2 2 1\n",
    "1 1 1 2 1 1 2 1\n",
    "1 2 1 1 1 1 2 1\n",
    "1 2 1 1 1 1 2 1\n",
    "1 2 1 2 1 2 2 1\n",
    "1 1 1 1 2 2 2 1\n",
    "1 1 1 2 2 2 0 0\n",
    "\n",
    "7 8 W 2\n",
    "\n",
    "するとこのようになると思います 上の8 x 8の数字は現在の盤面です また黒が2、白が1です0は空白を表しています\n",
    "\n",
    "この盤面に対して白が打った次の手が7 8(一番左上のマス目は(0,0)です)となります\n",
    "\n",
    "最後の2はあと何個空白スペースがあるかを表しています\n",
    "\n",
    "自分は勝った方のデータのみを用いて学習を行ったため\n",
    "\n",
    "テキストに入っているデータは全て勝利した人の手が書かれています\n",
    "\n",
    "またこの棋譜は\n",
    "\n",
    "https://www.skatgame.net/mburo/ggs/game-archive/Othello/\n",
    "\n",
    "を元に作成しました、オンラインオセロ対局のデータのようです\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-08T16:05:29.628Z"
    }
   },
   "outputs": [],
   "source": [
    "def transform(string,W):\n",
    "    flat = string.replace(\"\\n\", \"\").split(\" \")\n",
    "    state = np.array([int(flat[j]) for j in range(64)]).reshape(8,8)\n",
    "    if(W==1):\n",
    "      state=(3-state)%3\n",
    "    action = (int(flat[65])-1)*8 + int(flat[64])-1\n",
    "    return state, action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"data\\OthelloTeacher.txt\") as f:\n",
    "    data=f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "148718\n105074 43644\n"
    }
   ],
   "source": [
    "B_list=[];\n",
    "W_list=[];\n",
    "print(len(data))\n",
    "for line in data:\n",
    "    if \"B\" in line:\n",
    "        B_list.append(line)\n",
    "    else:\n",
    "        W_list.append(line)\n",
    "print(len(B_list),len(W_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_list=np.zeros([len(data),8,8])\n",
    "action_list=np.zeros([len(data)])\n",
    "for index,line in enumerate(data):\n",
    "    if \"B\" in line:\n",
    "        state,action=transform(line,0)\n",
    "    else:\n",
    "        state,action=transform(line,1)\n",
    "    state_list[index]=state\n",
    "    action_list[index]=action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_list_1=np.where(state_list==1,1,0)\n",
    "state_list_2=np.where(state_list==2,1,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "array([[0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 1, 0, 0],\n       [0, 0, 1, 1, 1, 0, 0, 0],\n       [0, 0, 0, 1, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0]])"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "array([[0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 1, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 1, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0]])"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "34.0"
     },
     "metadata": {}
    }
   ],
   "source": [
    "display(state_list_1[1],state_list_2[1],action_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "array([[[[0, 0, 0, ..., 0, 0, 0],\n         [0, 0, 0, ..., 0, 0, 0],\n         [0, 0, 0, ..., 0, 0, 0],\n         ...,\n         [0, 0, 0, ..., 0, 0, 0],\n         [0, 0, 0, ..., 0, 0, 0],\n         [0, 0, 0, ..., 0, 0, 0]],\n\n        [[0, 0, 0, ..., 0, 0, 0],\n         [0, 0, 0, ..., 0, 0, 0],\n         [0, 0, 0, ..., 1, 0, 0],\n         ...,\n         [0, 0, 0, ..., 0, 0, 0],\n         [0, 0, 0, ..., 0, 0, 0],\n         [0, 0, 0, ..., 0, 0, 0]],\n\n        [[0, 0, 0, ..., 0, 0, 0],\n         [0, 0, 0, ..., 0, 0, 0],\n         [0, 0, 0, ..., 1, 0, 0],\n         ...,\n         [0, 0, 1, ..., 0, 0, 0],\n         [0, 0, 0, ..., 0, 0, 0],\n         [0, 0, 0, ..., 0, 0, 0]],\n\n        ...,\n\n        [[0, 1, 1, ..., 1, 0, 1],\n         [1, 0, 1, ..., 1, 0, 1],\n         [1, 1, 1, ..., 0, 0, 1],\n         ...,\n         [1, 1, 0, ..., 0, 0, 1],\n         [0, 0, 0, ..., 0, 0, 0],\n         [1, 1, 1, ..., 1, 1, 1]],\n\n        [[0, 1, 1, ..., 1, 0, 1],\n         [1, 0, 1, ..., 0, 0, 1],\n         [1, 1, 1, ..., 0, 0, 1],\n         ...,\n         [1, 0, 0, ..., 0, 0, 1],\n         [0, 0, 0, ..., 0, 0, 0],\n         [1, 1, 1, ..., 1, 1, 1]],\n\n        [[0, 0, 0, ..., 0, 0, 1],\n         [0, 0, 1, ..., 0, 0, 1],\n         [0, 1, 1, ..., 0, 0, 1],\n         ...,\n         [0, 0, 0, ..., 0, 0, 1],\n         [0, 0, 0, ..., 0, 0, 0],\n         [1, 1, 1, ..., 1, 1, 1]]],\n\n\n       [[[0, 0, 0, ..., 0, 0, 0],\n         [0, 0, 0, ..., 0, 0, 0],\n         [0, 0, 0, ..., 0, 0, 0],\n         ...,\n         [0, 0, 0, ..., 0, 0, 0],\n         [0, 0, 0, ..., 0, 0, 0],\n         [0, 0, 0, ..., 0, 0, 0]],\n\n        [[0, 0, 0, ..., 0, 0, 0],\n         [0, 0, 0, ..., 0, 0, 0],\n         [0, 0, 0, ..., 0, 0, 0],\n         ...,\n         [0, 0, 0, ..., 0, 0, 0],\n         [0, 0, 0, ..., 0, 0, 0],\n         [0, 0, 0, ..., 0, 0, 0]],\n\n        [[0, 0, 0, ..., 0, 0, 0],\n         [0, 0, 0, ..., 0, 0, 0],\n         [0, 0, 0, ..., 0, 0, 0],\n         ...,\n         [0, 0, 0, ..., 0, 0, 0],\n         [0, 0, 0, ..., 0, 0, 0],\n         [0, 0, 0, ..., 0, 0, 0]],\n\n        ...,\n\n        [[0, 0, 0, ..., 0, 1, 0],\n         [0, 0, 0, ..., 0, 1, 0],\n         [0, 0, 0, ..., 1, 1, 0],\n         ...,\n         [0, 0, 1, ..., 1, 1, 0],\n         [0, 1, 1, ..., 1, 1, 1],\n         [0, 0, 0, ..., 0, 0, 0]],\n\n        [[0, 0, 0, ..., 0, 1, 0],\n         [0, 0, 0, ..., 1, 1, 0],\n         [0, 0, 0, ..., 1, 1, 0],\n         ...,\n         [0, 1, 1, ..., 1, 1, 0],\n         [1, 1, 1, ..., 1, 1, 1],\n         [0, 0, 0, ..., 0, 0, 0]],\n\n        [[1, 1, 1, ..., 1, 1, 0],\n         [1, 0, 0, ..., 1, 1, 0],\n         [1, 0, 0, ..., 1, 1, 0],\n         ...,\n         [1, 1, 1, ..., 1, 1, 0],\n         [1, 1, 1, ..., 1, 1, 1],\n         [0, 0, 0, ..., 0, 0, 0]]]])"
     },
     "metadata": {}
    }
   ],
   "source": [
    "train=np.array([state_list_1,state_list_2])\n",
    "display(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(8, 8, 2)),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(64, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Error when checking input: expected flatten_2_input to have shape (8, 8, 2) but got array with shape (148718, 8, 8)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-82-2f646e3ac68f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow36_conda\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow36_conda\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    233\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow36_conda\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[1;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    591\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    594\u001b[0m     \u001b[0mval_adapter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow36_conda\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[1;34m(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    644\u001b[0m     \u001b[0mstandardize_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m     x, y, sample_weights = standardize(\n\u001b[1;32m--> 646\u001b[1;33m         x, y, sample_weight=sample_weights)\n\u001b[0m\u001b[0;32m    647\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[0madapter_cls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mdata_adapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mListsOfScalarsDataAdapter\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m     \u001b[0mstandardize_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstandardize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow36_conda\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2381\u001b[0m         \u001b[0mis_dataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2382\u001b[0m         \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2383\u001b[1;33m         batch_size=batch_size)\n\u001b[0m\u001b[0;32m   2384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2385\u001b[0m   def _standardize_tensors(self, x, y, sample_weight, run_eagerly, dict_inputs,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow36_conda\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_tensors\u001b[1;34m(self, x, y, sample_weight, run_eagerly, dict_inputs, is_dataset, class_weight, batch_size)\u001b[0m\n\u001b[0;32m   2408\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2409\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2410\u001b[1;33m           exception_prefix='input')\n\u001b[0m\u001b[0;32m   2411\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2412\u001b[0m     \u001b[1;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow36_conda\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    580\u001b[0m                              \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m                              \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 582\u001b[1;33m                              str(data_shape))\n\u001b[0m\u001b[0;32m    583\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected flatten_2_input to have shape (8, 8, 2) but got array with shape (148718, 8, 8)"
     ]
    }
   ],
   "source": [
    "model.fit(train, action_list, epochs=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow36_conda",
   "language": "python",
   "name": "tensorflow36_conda"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}